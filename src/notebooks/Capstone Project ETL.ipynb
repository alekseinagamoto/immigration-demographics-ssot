{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "# Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to create a single-source-of-truth date warehouse that can serve as the foundation for creating logical data marts for analytics purposes on I94 immigration data, city temperatures data and U.S. demographics data.    \n",
    "\n",
    "The project contains the following steps:\n",
    "1. Scope the Project and Data\n",
    "2. Explore and Assess the Data\n",
    "3. Define the Data Model\n",
    "4. Run ETL to Model the Data\n",
    "5. Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "import os\n",
    "import logging\n",
    "import datetime as dt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, monotonically_increasing_id, year, month, to_date, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1. Project Scope and Data\n",
    "---\n",
    "\n",
    "#### Scope \n",
    "In order to create a single-source-of-truth data warehouse, the following steps are executed:\n",
    "\n",
    "* Load dataset into Spark dataframes\n",
    "* Exploratory data analysis of I94 immigration dataset to identify missing values, empty records, etc, informing the data preprocessing step downstream\n",
    "* Exploratory data analysis of U.S. city demographics dataset to identify missing values, empty records, etc, informing the data preprocessing step downstream \n",
    "* Exploratory data analysis of world temperatures dataset to identify missing values, empty records, etc, informing the data preprocessing step downstream \n",
    "* Execute data proprocessing tasks for all datasets\n",
    "* Create immigration fact table from preprocessed I94 immigration dataset \n",
    "* Create dimension tables:\n",
    "    * Create immigrant demographics dimension table from preprocessed I94 immigration dataset. Relates to immigration fact table by `cic_id` (unique record id) \n",
    "    * Create us city demographics dimension table from U.S. city demographics dataset. Relates to immigration fact table by `state_code`\n",
    "    * Create world temperature dimension table from preprocessed world temperature dataset. Relates to immigration fact table by composite key `city_name`\n",
    "    * Create country dimension table from `i94cit_i94res` data in the I94_SAS_Labels_Descriptions.SAS file\n",
    "    * Create city dimension table from `dim_i94port` data in the I94_SAS_Labels_Descriptions.SAS file\n",
    "    * Create state dimension table from `dim_i94addr` data in I94_SAS_Labels_Descriptions.SAS file\n",
    "    \n",
    "##### Datasets:\n",
    "\n",
    "| Data Set | Format  | Description |\n",
    "|  :-     |  :-    |  :-        |\n",
    "|[I94 Immigration Data](https://www.trade.gov/national-travel-and-tourism-office)| SAS | Dataset contains international visitor arrival statistics by world regions, mode of transportation, port of entry, demographics, visa type, etc.|\n",
    "|[World Temperature Data](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data)| CSV | Dataset contains monthly average temperatures by city.|\n",
    "|[U.S. City Demographic Data](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)| CSV | Dataset contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000.|\n",
    "\n",
    "##### Tech Stack:\n",
    "We've made use of the followng technologies in this project: \n",
    "- [AWS S3](https://aws.amazon.com/s3/): data storage\n",
    "- Apache Spark ([PySpark](https://spark.apache.org/docs/latest/api/python/#:~:text=PySpark%20is%20an%20interface%20for,data%20in%20a%20distributed%20environment.)): for reading data from the source (e.g. customer systems / internal systems etc), preprocessing the data and creates fact and dimension tables, and writing the data into fact and dimension tabls on S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2. Load and Preprocess Data\n",
    "\n",
    "* Load datasets into Spark dataframes\n",
    "* Remove duplicates, empty rows and columns with significant amount of missing values (>85%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### I94 Immigration Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Load I94 Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data for April 2016\n",
    "file_name = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df_immi_raw = spark.read.format('com.github.saurfang.sas.spark').load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records\n",
    "df_immi_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "df_immi_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top five records\n",
    "df_immi_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Data dictionary\n",
    "\n",
    "| Field Name | Description |\n",
    "|  :-      |  :-        |\n",
    "| cicid    | Unique record ID |\n",
    "|i94yr     | 4  digit year|\n",
    "|i94mon| Numeric month |\n",
    "|i94cit|3 digit code for immigrant country of birth|\n",
    "|i94res|3 digit code for immigrant country of residence|\n",
    "|i94port|Port of admission|\n",
    "|arrdate|Arrival Date in the USA|\n",
    "|i94mode|Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)|\n",
    "|i94addr|USA State of arrival|\n",
    "|depdate|Departure Date from the USA|\n",
    "|i94bir|Age of Respondent in Years|\n",
    "|i94visa|Visa codes collapsed into three categories|\n",
    "|count|Field used for summary statistics|\n",
    "|dtadfile|Character Date Field - Date added to I-94 Files|\n",
    "|visapost|Department of State where where Visa was issued|\n",
    "|occup|Occupation that will be performed in U.S|\n",
    "|entdepa|Arrival Flag - admitted or paroled into the U.S.|\n",
    "|entdepd|Departure Flag - Departed, lost I-94 or is deceased|\n",
    "|entdepu|Update Flag - Either apprehended, overstayed, adjusted to perm residence|\n",
    "|matflag|Match flag - Match of arrival and departure records|\n",
    "|biryear|4 digit year of birth|\n",
    "|dtaddto|Character Date Field - Date to which admitted to U.S. (allowed to stay until)|\n",
    "|gender|Non-immigrant sex|\n",
    "|insnum|INS number|\n",
    "|airline|Airline used to arrive in U.S.|\n",
    "|admnum|Admission Number|\n",
    "|fltno|Flight number of Airline used to arrive in U.S.|\n",
    "|visatype|Class of admission legally admitting the non-immigrant to temporarily stay in U.S.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Preprocess I94 Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Columns with +85% missing values (as identified in EDA notebook)\n",
    "cols = ['entdepu', 'occup', 'insnum']\n",
    "\n",
    "# Drop columns\n",
    "df_immi_clean = df_immi_raw.drop(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "df_immi_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates on unique identifier 'cicid'\n",
    "df_immi_clean = df_immi_clean.dropDuplicates(['cicid'])\n",
    "df_immi_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop records missing unique identifier 'cicid'\n",
    "df_immi_clean = df_immi_clean.dropna(how='all', subset=['cicid'])\n",
    "df_immi_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_immigration_data(df):\n",
    "    \"\"\"Preprocess immigration dataframe\n",
    "    :param df: spark dataframe with immigration data\n",
    "    :return: spark dataframe with preprocessed immigration data\n",
    "    \"\"\"    \n",
    "    logging.info(f'Total records in raw dataframe: {df.count()}')\n",
    "    print(f'Total records in raw dataframe: {df.count()}')\n",
    "    \n",
    "    # Remove columns with +85% missing values as identified during EDA\n",
    "    drop_columns = ['entdepu', 'occup', 'insnum']    \n",
    "    df = df.drop(*drop_columns)\n",
    "    \n",
    "    # Remove duplicate records on 'cicid'\n",
    "    df = df.dropDuplicates(['cicid'])\n",
    "    \n",
    "    # Remove empty records\n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    logging.info(f'Total records in preprocessed dataframe: {df.count()}')\n",
    "    print(f'Total records in preprocessed dataframe: {df.count()}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in raw dataframe: 3096313\n",
      "Total records in preprocessed dataframe: 3096313\n"
     ]
    }
   ],
   "source": [
    "df_immi_clean = preprocess_immigration_data(df_immi_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### World Temperature data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Load World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_name = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature_raw = spark.read.csv(file_name, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records\n",
    "df_temperature_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "df_temperature_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top five records\n",
    "df_temperature_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Data dictionary\n",
    "| Field Name | Description |\n",
    "|  :-      |  :-        |\n",
    "|dt|Date|\n",
    "|AverageTemperature|Global average city temperature in celsius|\n",
    "|AverageTemperatureUncertainty|95% confidence interval around the average|\n",
    "|City|Name of city|\n",
    "|Country|Name of country|\n",
    "|Latitude|City latitude|\n",
    "|Longitude|City longitude|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Preprocess World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_temperature_data(df):\n",
    "    \"\"\"Preprocess world temperature dataset to remove records with missing values and duplicates\n",
    "    \n",
    "    :param df: spark dataframe with world temperature data\n",
    "    :return: spark dataframe with preprocessed world temperature data\n",
    "    \"\"\"\n",
    "    logging.info(f'Total records in raw dataframe: {df.count()}')\n",
    "    print(f'Total records in raw dataframe: {df.count()}')\n",
    "    \n",
    "    # Remove records with missing average temperature\n",
    "    df = df.dropna(subset=['AverageTemperature'])\n",
    "    \n",
    "    # Remove duplicate records on date, city and country\n",
    "    df = df.dropDuplicates(subset=['dt', 'City', 'Country'])\n",
    "    \n",
    "    # Remove empty rows\n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    logging.info(f'Total records in preprocessed dataframe: {df.count()}')\n",
    "    print(f'Total records in preprocessed dataframe: {df.count()}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in raw dataframe: 8599212\n",
      "Total records in preprocessed dataframe: 8190783\n"
     ]
    }
   ],
   "source": [
    "df_temperature_clean = preprocess_temperature_data(df_temperature_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### U.S. City Demographic data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Load U.S. City Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_name = \"us-cities-demographics.csv\"\n",
    "df_demo_raw = spark.read.csv(file_name, inferSchema=True, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records\n",
    "df_demo_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "df_demo_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top five records\n",
    "df_demo_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Data dictionary\n",
    "| Field Name | Description |\n",
    "|  :-      |  :-        |\n",
    "|City|City Name|\n",
    "|State|US State where city is located|\n",
    "|Median Age|Median age of the population|\n",
    "|Male Population|Count of male population|\n",
    "|Female Population|Count of female population|\n",
    "|Total Population|Count of total population|\n",
    "|Number of Veterans|Count of total Veterans|\n",
    "|Foreign born|Count of residents of the city that were not born in the city|\n",
    "|Average Household Size|Average city household size|\n",
    "|State Code|Code of the US state|\n",
    "|Race|Respondent race|\n",
    "|Count|Count of city's individual per race|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Preprocess U.S. Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_demographics_data(df):\n",
    "    \"\"\"Preprocess US demographics dataset to remove records with missing values and duplicates\n",
    "    \n",
    "    :param df: spark dataframe with us demograpgics data\n",
    "    :return: spark dataframe with processed us demograpgics data\n",
    "    \"\"\"\n",
    "    logging.info(f'Total records in raw dataframe: {df.count()}')\n",
    "    print(f'Total records in raw dataframe: {df.count()}')\n",
    "    \n",
    "    # Remove duplicate records on city, state and race\n",
    "    df = df.dropDuplicates(subset=['City', 'State', 'Race'])\n",
    "    \n",
    "    # Remove empty rows\n",
    "    df.dropna(how=\"all\")\n",
    "    \n",
    "    logging.info(f'Total records in preprocessed dataframe: {df.count()}')\n",
    "    print(f'Total records in preprocessed dataframe: {df.count()}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in raw dataframe: 2891\n",
      "Total records in preprocessed dataframe: 2891\n"
     ]
    }
   ],
   "source": [
    "df_demo_clean = preprocess_demographics_data(df_demo_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport Code data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Load U.S. City Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_name = \"airport-codes_csv.csv\"\n",
    "df_airport_raw = spark.read.csv(file_name, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55075"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records\n",
    "df_airport_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "df_airport_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport            11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport          3435   \n",
       "2  00AK  small_airport                        Lowell Field           450   \n",
       "3  00AL  small_airport                        Epps Airpark           820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport           237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top five records\n",
    "df_airport_raw.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Data dictionary\n",
    "| Field Name | Description |\n",
    "|  :-      |  :-        |\n",
    "|ident| Unique ID |\n",
    "|type |Type of airport|\n",
    "|name |Airport name|\n",
    "|elevation_ft |Airport elevation in feet|\n",
    "|Continent | Continent|\n",
    "|iso_country| ISO country code|\n",
    "|iso_region|ISO region code|\n",
    "|municipality|Municipality name|\n",
    "|gps_code | GPS code|\n",
    "|iata_code|Three-character alphanumeric geocode designating airport |\n",
    "|local_code| Local code|\n",
    "|coordinates| Airport Longitude and Latitude|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3. Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The conceptual data model for our single-source-of-truth datawarehouse looks as follows:\n",
    "\n",
    "<img src=\"erd_data_warehouse.png\" alt=\"Conceptual model\" width=\"1500\" height=\"1500\" />\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The data pipeline is as follows:\n",
    "\n",
    "1. Load datasets stored in S3 buckets into Spark dataframes:\n",
    "    - [Source_S3_Bucket]/immigration_data/18-83510-I94-Data-2016/*.sas7bdat\n",
    "    - [Source_S3_Bucket]/I94_SAS_labels_data/I94_SAS_Labels_Descriptions.SAS\n",
    "    - [Source_S3_Bucket]/temperature_data/GlobalLandTemperaturesByCity.csv\n",
    "    - [Source_S3_Bucket]/us_demographics_data/us-cities-demographics.csv\n",
    "    \n",
    "\n",
    "2. Create helper dimension tables from I94_SAS_Labels_Descriptinons.SAS file\n",
    "    - Create country dimension table from `i94cit_i94res` data in the I94_SAS_Labels_Descriptions.SAS file\n",
    "    - Create city dimension table from `dim_i94port` data in the I94_SAS_Labels_Descriptions.SAS file\n",
    "    - Create state dimension table from `dim_i94addr` data in I94_SAS_Labels_Descriptions.SAS file\n",
    "\n",
    "3. Preprocess I94 Immigration data\n",
    "4. Create I94 Immigration fact table - `fact_immigration` - from preprocessed I94 Immigration data  \n",
    "5. Create I94 Immigration demographics dimension table - `dim_immigrant_demographics` - from preprocessed I94 Immigration data \n",
    "6. Create U.S. City Demographic dimension table - `dim_city_demographics` - from U.S. City Demographic data\n",
    "7. Preprocess World Temperature data\n",
    "8. Create World Temperature dimension table - `dim_city_temperature` - from preprocessed World Temperature data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4. Run Pipelines to Model the Data \n",
    "\n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Specify output path (target bucket on S3)\n",
    "output_data = 'tables/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create Immigration fact table\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_immigration_fact_table(df, output_data):\n",
    "    \"\"\"Creates an immigration fact table from  I94 Immigration data.\n",
    "    \n",
    "    :param df: spark dataframe with preprocessed immigration data\n",
    "    :param output_data: write path\n",
    "    :return: spark dataframe with immigration fact data\n",
    "    \"\"\"    \n",
    "    # UDF to convert SAS date format to datetime object\n",
    "    get_datetime = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(x)).isoformat() if x else None)\n",
    "    \n",
    "    df = df.withColumnRenamed('cicid', 'cic_id') \\\n",
    "           .withColumnRenamed('i94yr', 'year') \\\n",
    "           .withColumnRenamed('i94mon', 'month') \\\n",
    "           .withColumnRenamed('i94port', 'city_code') \\\n",
    "           .withColumnRenamed('i94addr', 'state_code') \\\n",
    "           .withColumnRenamed('arrdate', 'arrival_date') \\\n",
    "           .withColumnRenamed('depdate', 'departure_date') \\\n",
    "           .withColumnRenamed('i94mode', 'mode') \\\n",
    "           .withColumnRenamed('i94visa', 'visa') \\\n",
    "           .withColumnRenamed('visatype', 'visa_type')\n",
    "    \n",
    "    # convert dates into datetime objects\n",
    "    df = df.withColumn('arrival_date', get_datetime(df.arrival_date))\n",
    "    df = df.withColumn('departure_date', get_datetime(df.departure_date))\n",
    "    \n",
    "    df = df.withColumn('immigration_id', monotonically_increasing_id())\n",
    "    \n",
    "    # write fact table to parquet file partioned by state\n",
    "    df.write.mode('overwrite').partitionBy('state_code').parquet(path=output_data + \"fact_immigration\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>city_code</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>mode</th>\n",
       "      <th>state_code</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>immigration_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>5.542587e+10</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>5.542582e+10</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>5.542862e+10</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.543331e+10</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NAS</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>5.540611e+10</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cic_id    year  month  i94cit  i94res city_code arrival_date  mode  \\\n",
       "0   299.0  2016.0    4.0   103.0   103.0       NYC   2016-04-01   1.0   \n",
       "1   305.0  2016.0    4.0   103.0   103.0       NYC   2016-04-01   1.0   \n",
       "2   496.0  2016.0    4.0   103.0   103.0       CHI   2016-04-01   1.0   \n",
       "3   558.0  2016.0    4.0   103.0   103.0       SFR   2016-04-01   1.0   \n",
       "4   596.0  2016.0    4.0   103.0   103.0       NAS   2016-04-01   1.0   \n",
       "\n",
       "  state_code departure_date      ...        entdepd  matflag  biryear  \\\n",
       "0         NY     2016-04-06      ...              O        M   1962.0   \n",
       "1         NY     2016-04-11      ...              O        M   1953.0   \n",
       "2         IL     2016-04-04      ...              O        M   1952.0   \n",
       "3         CA     2016-04-03      ...              O        M   1974.0   \n",
       "4         FL     2016-04-03      ...              N        M   1992.0   \n",
       "\n",
       "    dtaddto gender airline        admnum  fltno  visa_type immigration_id  \n",
       "0  06292016   None      OS  5.542587e+10  00087         WT              0  \n",
       "1  06292016   None      OS  5.542582e+10  00087         WT              1  \n",
       "2  06292016   None      OS  5.542862e+10  00065         WB              2  \n",
       "3  06292016      M      LH  5.543331e+10  00454         WB              3  \n",
       "4  06292016      M      UP  5.540611e+10  00221         WT              4  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi_fact_df = create_immigration_fact_table(df_immi_clean, output_data)\n",
    "immi_fact_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create Immigrant Demographics dimension table\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_immi_demographics_dim_table(df, output_data):\n",
    "    \"\"\"Creates an immigrant demographics dim table from  I94 Immigration data.\n",
    "    \n",
    "    :param df: spark dataframe of immigration data\n",
    "    :param output_data: write path\n",
    "    :return: spark dataframe with immigrant demographics fact data\n",
    "    \"\"\"    \n",
    "    df = df.withColumnRenamed('cicid','cic_id') \\\n",
    "           .withColumnRenamed('i94cit', 'country_of_birth') \\\n",
    "           .withColumnRenamed('i94res', 'country_of_residence') \\\n",
    "           .withColumnRenamed('biryear', 'year_of_birth') \\\n",
    "           .withColumnRenamed('ins_num', 'insnum')\n",
    "    \n",
    "    df = df.withColumn('immi_demographics_id', monotonically_increasing_id())\n",
    "    \n",
    "    # write dimension table to parquet file\n",
    "    df.write.mode('overwrite').parquet(path=output_data + \"dim_immigrant_demographics\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>country_of_birth</th>\n",
       "      <th>country_of_residence</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>immi_demographics_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>5.542587e+10</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>305.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>5.542582e+10</td>\n",
       "      <td>00087</td>\n",
       "      <td>WT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>5.542862e+10</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.543331e+10</td>\n",
       "      <td>00454</td>\n",
       "      <td>WB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>596.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>M</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>5.540611e+10</td>\n",
       "      <td>00221</td>\n",
       "      <td>WT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cic_id   i94yr  i94mon  country_of_birth  country_of_residence i94port  \\\n",
       "0   299.0  2016.0     4.0             103.0                 103.0     NYC   \n",
       "1   305.0  2016.0     4.0             103.0                 103.0     NYC   \n",
       "2   496.0  2016.0     4.0             103.0                 103.0     CHI   \n",
       "3   558.0  2016.0     4.0             103.0                 103.0     SFR   \n",
       "4   596.0  2016.0     4.0             103.0                 103.0     NAS   \n",
       "\n",
       "   arrdate  i94mode i94addr  depdate         ...           entdepd  matflag  \\\n",
       "0  20545.0      1.0      NY  20550.0         ...                 O        M   \n",
       "1  20545.0      1.0      NY  20555.0         ...                 O        M   \n",
       "2  20545.0      1.0      IL  20548.0         ...                 O        M   \n",
       "3  20545.0      1.0      CA  20547.0         ...                 O        M   \n",
       "4  20545.0      1.0      FL  20547.0         ...                 N        M   \n",
       "\n",
       "   year_of_birth   dtaddto gender airline        admnum  fltno  visatype  \\\n",
       "0         1962.0  06292016   None      OS  5.542587e+10  00087        WT   \n",
       "1         1953.0  06292016   None      OS  5.542582e+10  00087        WT   \n",
       "2         1952.0  06292016   None      OS  5.542862e+10  00065        WB   \n",
       "3         1974.0  06292016      M      LH  5.543331e+10  00454        WB   \n",
       "4         1992.0  06292016      M      UP  5.540611e+10  00221        WT   \n",
       "\n",
       "  immi_demographics_id  \n",
       "0                    0  \n",
       "1                    1  \n",
       "2                    2  \n",
       "3                    3  \n",
       "4                    4  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi_demo_dim_df = create_immi_demographics_dim_table(df_immi_clean, output_data)\n",
    "immi_demo_dim_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create City Demographics dimension table\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_city_demographics_dimension_table(df, output_data):\n",
    "    \"\"\"Creates a us city demographics dimension table from the U.S. City Demographic dataset.\n",
    "    \n",
    "    :param df: spark dataframe of us city demographics data\n",
    "    :param output_data: write path\n",
    "    :return: spark dataframe with demographics data\n",
    "    \"\"\"\n",
    "    df = df.withColumnRenamed('City', 'city_code') \\\n",
    "           .withColumnRenamed('State Code', 'state_code') \\\n",
    "           .withColumnRenamed('Median Age','median_age') \\\n",
    "           .withColumnRenamed('Male Population', 'male_population') \\\n",
    "           .withColumnRenamed('Female Population', 'female_population') \\\n",
    "           .withColumnRenamed('Total Population', 'total_population') \\\n",
    "           .withColumnRenamed('Number of Veterans', 'number_of_veterans') \\\n",
    "           .withColumnRenamed('Foreign-born', 'foreign_born_num') \\\n",
    "           .withColumnRenamed('Average Household Size', 'avg_household_size') \\\n",
    "           .withColumnRenamed('Race', 'race') \\\n",
    "           .withColumnRenamed('Count', 'count')\n",
    "\n",
    "    df = df.withColumn('id', monotonically_increasing_id())\n",
    "    \n",
    "    # write dimension table to parquet file\n",
    "    df.write.mode('overwrite').parquet(path=output_data + \"dim_city_demographics\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>State</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born_num</th>\n",
       "      <th>avg_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alafaya</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33.5</td>\n",
       "      <td>39504</td>\n",
       "      <td>45760</td>\n",
       "      <td>85264</td>\n",
       "      <td>4176</td>\n",
       "      <td>15842</td>\n",
       "      <td>2.94</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>63666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>California</td>\n",
       "      <td>35.8</td>\n",
       "      <td>38747</td>\n",
       "      <td>38309</td>\n",
       "      <td>77056</td>\n",
       "      <td>780</td>\n",
       "      <td>34322</td>\n",
       "      <td>4.13</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>1560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.6</td>\n",
       "      <td>1149686</td>\n",
       "      <td>1148942</td>\n",
       "      <td>2298628</td>\n",
       "      <td>71898</td>\n",
       "      <td>696210</td>\n",
       "      <td>2.66</td>\n",
       "      <td>TX</td>\n",
       "      <td>Asian</td>\n",
       "      <td>173854</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Las Cruces</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>32.7</td>\n",
       "      <td>47835</td>\n",
       "      <td>53809</td>\n",
       "      <td>101644</td>\n",
       "      <td>9421</td>\n",
       "      <td>11888</td>\n",
       "      <td>2.58</td>\n",
       "      <td>NM</td>\n",
       "      <td>White</td>\n",
       "      <td>91201</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Missouri City</td>\n",
       "      <td>Texas</td>\n",
       "      <td>37.2</td>\n",
       "      <td>34932</td>\n",
       "      <td>36846</td>\n",
       "      <td>71778</td>\n",
       "      <td>4274</td>\n",
       "      <td>18556</td>\n",
       "      <td>3.03</td>\n",
       "      <td>TX</td>\n",
       "      <td>Asian</td>\n",
       "      <td>17854</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city_code       State  median_age  male_population  female_population  \\\n",
       "0        Alafaya     Florida        33.5            39504              45760   \n",
       "1   Baldwin Park  California        35.8            38747              38309   \n",
       "2        Houston       Texas        32.6          1149686            1148942   \n",
       "3     Las Cruces  New Mexico        32.7            47835              53809   \n",
       "4  Missouri City       Texas        37.2            34932              36846   \n",
       "\n",
       "   total_population  number_of_veterans  foreign_born_num  avg_household_size  \\\n",
       "0             85264                4176             15842                2.94   \n",
       "1             77056                 780             34322                4.13   \n",
       "2           2298628               71898            696210                2.66   \n",
       "3            101644                9421             11888                2.58   \n",
       "4             71778                4274             18556                3.03   \n",
       "\n",
       "  state_code                       race   count  id  \n",
       "0         FL                      White   63666   0  \n",
       "1         CA  Black or African-American    1560   1  \n",
       "2         TX                      Asian  173854   2  \n",
       "3         NM                      White   91201   3  \n",
       "4         TX                      Asian   17854   4  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_dim_df = create_city_demographics_dimension_table(df_demo_clean, output_data)\n",
    "demo_dim_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create Global Temperature dimension table\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_temperature_dimension_table(df, output_data):\n",
    "    \"\"\"Creates a global temperature dimension table from the Global Average Temperature dataset.\n",
    "    \n",
    "    :param df: spark dataframe of global average temperature by city data\n",
    "    :param output_data: write path\n",
    "    :return: spark dataframe with average temperature by city data\n",
    "    \"\"\"\n",
    "    df = df.withColumn('dt', to_date(col('dt'))) \\\n",
    "           .withColumnRenamed('City', 'city_name') \\\n",
    "           .withColumnRenamed('Country', 'country_name') \\\n",
    "           .withColumnRenamed('AverageTemperature','avg_temperature') \\\n",
    "           .withColumnRenamed('AverageTemperatureUncertainty', 'avg_temperature_delta')\n",
    "    \n",
    "    # Derive month and year from datetime column \n",
    "    df = df.withColumn('year', year(df['dt']))\n",
    "    df = df.withColumn('month', month(df['dt']))\n",
    "\n",
    "    # write dimension table to parquet file\n",
    "    df.write.mode('overwrite').parquet(path=output_data + \"dim_temperature\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>avg_temperature_delta</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>5.354</td>\n",
       "      <td>1.636</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50.63N</td>\n",
       "      <td>8.87E</td>\n",
       "      <td>1743</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>7.030</td>\n",
       "      <td>1.611</td>\n",
       "      <td>Münster</td>\n",
       "      <td>Germany</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>7.88E</td>\n",
       "      <td>1743</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>5.044</td>\n",
       "      <td>2.222</td>\n",
       "      <td>Pitesti</td>\n",
       "      <td>Romania</td>\n",
       "      <td>44.20N</td>\n",
       "      <td>24.60E</td>\n",
       "      <td>1743</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>13.808</td>\n",
       "      <td>1.918</td>\n",
       "      <td>Sabadell</td>\n",
       "      <td>Spain</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>2.13E</td>\n",
       "      <td>1743</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>10.352</td>\n",
       "      <td>2.222</td>\n",
       "      <td>Akron</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>80.95W</td>\n",
       "      <td>1744</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  avg_temperature  avg_temperature_delta  city_name  \\\n",
       "0  1743-11-01            5.354                  1.636  Frankfurt   \n",
       "1  1743-11-01            7.030                  1.611    Münster   \n",
       "2  1743-11-01            5.044                  2.222    Pitesti   \n",
       "3  1743-11-01           13.808                  1.918   Sabadell   \n",
       "4  1744-04-01           10.352                  2.222      Akron   \n",
       "\n",
       "    country_name Latitude Longitude  year  month  \n",
       "0        Germany   50.63N     8.87E  1743     11  \n",
       "1        Germany   52.24N     7.88E  1743     11  \n",
       "2        Romania   44.20N    24.60E  1743     11  \n",
       "3          Spain   40.99N     2.13E  1743     11  \n",
       "4  United States   40.99N    80.95W  1744      4  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_dim_df = create_temperature_dimension_table(df_temperature_clean, output_data)\n",
    "temperature_dim_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### I94 SAS Labels Descriptions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create `dim_country` table from `i94cit_i94res` data in I94_SAS_Labels_Descriptinons.SAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94cit_i94res = {}\n",
    "for countries in contents[9:298]:\n",
    "    pair = countries.split('=')\n",
    "    country_code, country_name = pair[0].strip(), pair[1].strip().strip(\"'\")\n",
    "    i94cit_i94res[country_code] = country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code                                       country_name\n",
       "0          582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1          236                                        AFGHANISTAN\n",
       "2          101                                            ALBANIA\n",
       "3          316                                            ALGERIA\n",
       "4          102                                            ANDORRA"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94cit_i94res = pd.DataFrame(list(i94cit_i94res.items()), columns=['country_code', 'country_name'])\n",
    "df_i94cit_i94res.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(i94cit_i94res.items(), ['country_code', 'country_name'])\\\n",
    "    .write.mode(\"overwrite\")\\\n",
    "    .parquet(path=output_data + 'dim_country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create `dim_city` table from `dim_i94port` data in I94_SAS_Labels_Descriptinons.SAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94port = {}\n",
    "for cities in contents[302:962]:\n",
    "    pair = cities.split('=')\n",
    "    city_code, city_name = pair[0].strip(\"\\t\").strip().strip(\"'\"), pair[1].strip('\\t').strip().strip(\"''\")\n",
    "    i94port[city_code] = city_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94port = pd.DataFrame(list(i94port.items()), columns=['city_code', 'city_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94port[['city_name', 'state_code']] = df_i94port['city_name'].str.split(',', 1, expand=True)\n",
    "df_i94port['city_name'] = df_i94port['city_name'].str.title()\n",
    "df_i94port.drop(columns='state_code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(df_i94port)\\\n",
    "    .write.mode(\"overwrite\")\\\n",
    "    .parquet(path=output_data + 'dim_city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>city_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>Alcan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>Anchorage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>Baker Aaf - Baker Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>Daltons Cache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>Dew Station Pt Lay Dew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_code                 city_name\n",
       "0       ALC                     Alcan\n",
       "1       ANC                 Anchorage\n",
       "2       BAR  Baker Aaf - Baker Island\n",
       "3       DAC             Daltons Cache\n",
       "4       PIZ    Dew Station Pt Lay Dew"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94port.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create `dim_state` table from `dim_i94addr` data in I94_SAS_Labels_Descriptinons.SAS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94addr = {}\n",
    "for states in contents[981:1036]:\n",
    "    pair = states.split('=')\n",
    "    state_code, state_name = pair[0].strip('\\t').strip(\"'\"), pair[1].strip().strip(\"'\")\n",
    "    i94addr[state_code] = state_name.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  state_name\n",
       "0         AL     Alabama\n",
       "1         AK      Alaska\n",
       "2         AZ     Arizona\n",
       "3         AR    Arkansas\n",
       "4         CA  California"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94addr = pd.DataFrame(list(i94addr.items()), columns=['state_code', 'state_name'])\n",
    "df_i94addr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(df_i94addr)\\\n",
    "    .write.mode(\"overwrite\")\\\n",
    "    .parquet(path=output_data + 'dim_state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Run data quality check for data completened: verify ETL process has created and populated fact and dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_quality_check(df, table_name):\n",
    "    \"\"\"Check for non-empty fact and dimension tables.\n",
    "    :param df: spark dataframe\n",
    "    :param table_name: table name\n",
    "    \"\"\"\n",
    "    total_count = df.count()\n",
    "\n",
    "    if total_count == 0:\n",
    "        print(f\"Data quality check FAILED for {table_name}: no records found!\")\n",
    "        logging.warning(f\"Data quality check FAILED for {table_name}: no records found!\")\n",
    "    else:\n",
    "        print(f\"Data quality check PASSED for {table_name}: {total_count} records found!\")\n",
    "        logging.info(f\"Data quality check PASSED for {table_name}: {total_count} records found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration_fact: 3096313 records found!\n",
      "Data quality check passed for immigrant_demographics_dim: 3096313 records found!\n",
      "Data quality check passed for demographics_dim: 2891 records found!\n"
     ]
    }
   ],
   "source": [
    "tables_dict = {\n",
    "    'immigration_fact': immi_fact_df,\n",
    "    'immigrant_demographics_dim': immi_demo_dim_df,\n",
    "    'demographics_dim': demo_dim_df\n",
    "}\n",
    "\n",
    "for table_name, df in tables_dict.items():\n",
    "    run_quality_check(df, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data Dictionary of the Data Model \n",
    "\n",
    "\n",
    "<img src=\"data_dictionary.png\" width=\"1500\" height=\"1500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 5. Project Write Up\n",
    "\n",
    "##### 5.1 The rationale for the chosen tools and technologies\n",
    "* [AWS S3](https://aws.amazon.com/s3/) for data storage.\n",
    "* Apache Spark ([PySpark](https://spark.apache.org/docs/latest/api/python/#:~:text=PySpark%20is%20an%20interface%20for,data%20in%20a%20distributed%20environment.)) processing the data and creating fact and dimension tables.\n",
    "\n",
    "##### 5.2 Data update frequency\n",
    "* The immigration fact and immigrant demographics dimension table, and temperature table should be updated on a monthly schedule as the raw data is aggregated on a monthly time period.\n",
    "* The US city demographics table can be updated depending on the refresh time period of the raw data, which, given how involved it is to update census data, probably annually.\n",
    "\n",
    "##### 5.3 Future work\n",
    "5.3.1 The data was increased by 100x\n",
    "* It seems unlikely that a 100x increase in the data size would be efficiently processes by Apache Spark in standalone server mode and a cloud big data plaform for running large-scale distributed processing jobs such as [Amazon EMR](https://aws.amazon.com/emr/) should be considered to scale.\n",
    "\n",
    "5.3.2 The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "* [Apache Airflow](https://airflow.apache.org/) can be used for building out an ETL data pipeline that automates the tasks of processing fresh data and updating the dashboard on a daily basis by 7am.   \n",
    " \n",
    "5.3.3 The database needed to be accessed by 100+ people.\n",
    "* In this scenario we would move our single-source-of-truth database to a cloud dataware house such as [Amazon Redshift](https://aws.amazon.com/redshift/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
